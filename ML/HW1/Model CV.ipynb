{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\shcherbakov2-ia\\AppData\\Local\\Continuum\\Anaconda3\\lib\\site-packages\\pandas\\compat\\_optional.py:106: UserWarning: Pandas requires version '1.2.1' or newer of 'bottleneck' (version '1.2.0' currently installed).\n",
      "  warnings.warn(msg, UserWarning)\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import GridSearchCV, PredefinedSplit\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# чтение данных "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>y</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1722</td>\n",
       "      <td>even the \" shorter \" battery life , though , h...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1217</td>\n",
       "      <td>video output stopped workin .</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>519</td>\n",
       "      <td>flawless .</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1132</td>\n",
       "      <td>my experience with installation was quite good .</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1665</td>\n",
       "      <td>the box included a little polyester , pull-str...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                   text  y\n",
       "1722  even the \" shorter \" battery life , though , h...  0\n",
       "1217                     video output stopped workin .   0\n",
       "519                                          flawless .  1\n",
       "1132   my experience with installation was quite good .  1\n",
       "1665  the box included a little polyester , pull-str...  0"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train = pd.read_csv('data/products_sentiment_train.tsv', sep='\\t', header=None)\n",
    "train.columns = ['text', 'y']\n",
    "train, hold = train_test_split(train, test_size=0.3, stratify=train['y'])\n",
    "train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Id</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>so , why the small digital elph , rather than ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>3/4 way through the first disk we played on it...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>better for the zen micro is outlook compatibil...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>6 . play gameboy color games on it with goboy .</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>likewise , i 've heard norton 2004 professiona...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Id                                               text\n",
       "0   0  so , why the small digital elph , rather than ...\n",
       "1   1  3/4 way through the first disk we played on it...\n",
       "2   2  better for the zen micro is outlook compatibil...\n",
       "3   3    6 . play gameboy color games on it with goboy .\n",
       "4   4  likewise , i 've heard norton 2004 professiona..."
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test = pd.read_csv('data/products_sentiment_test.tsv', sep='\\t')\n",
    "test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1400, 2)\n",
      "(600, 2)\n",
      "(500, 2)\n"
     ]
    }
   ],
   "source": [
    "print(train.shape)\n",
    "print(hold.shape)\n",
    "print(test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Чистка"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# подключение модулей\n",
    "lemm_enabled = False\n",
    "stem_enabled = False"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Удаляем пунктуацию"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import string\n",
    "def remove_punctuation(text):\n",
    "    no_punct = \"\".join([c for c in text if c not in string.punctuation])\n",
    "    return no_punct\n",
    "\n",
    "train['text'] = train['text'].apply(remove_punctuation)\n",
    "hold['text'] = hold['text'].apply(remove_punctuation)\n",
    "test['text'] = test['text'].apply(remove_punctuation)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Токенизируем"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from nltk.tokenize import RegexpTokenizer\n",
    "tokenizer = RegexpTokenizer(r'\\w+')\n",
    "\n",
    "def tokenize(text):\n",
    "    return tokenizer.tokenize(text.lower())\n",
    "\n",
    "train['text_tokenized'] = train['text'].apply(tokenize)\n",
    "hold['text_tokenized'] = hold['text'].apply(tokenize)\n",
    "test['text_tokenized'] = test['text'].apply(tokenize)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Стоп слова"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "with open('data/stopwords.txt', 'r') as f:\n",
    "    stopwords = f.read().split('\\n')\n",
    "    \n",
    "def remove_stopwords(text_arr):\n",
    "    return [w for w in text_arr if w not in stopwords]\n",
    "    \n",
    "train['text_tokenized'] = train['text_tokenized'].apply(remove_stopwords)\n",
    "hold['text_tokenized'] = hold['text_tokenized'].apply(remove_stopwords)\n",
    "test['text_tokenized'] = test['text_tokenized'].apply(remove_stopwords)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## лематизация"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "\n",
    "if lemm_enabled:\n",
    "    from nltk.stem import WordNetLemmatizer\n",
    "    lemmatizer = WordNetLemmatizer()\n",
    "\n",
    "    def word_lemmatizer(text):\n",
    "        lem_text = [lemmatizer.lemmatize(i) for i in text]\n",
    "        return lem_text\n",
    "    \n",
    "    train['text_tokenized'] = train['text_tokenized'].apply(word_lemmatizer)\n",
    "    hold['text_tokenized'] = hold['text_tokenized'].apply(word_lemmatizer)\n",
    "    test['text_tokenized'] = test['text_tokenized'].apply(word_lemmatizer)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Stemming"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from nltk.stem import PorterStemmer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "if stem_enabled:\n",
    "    from nltk.stem import PorterStemmer\n",
    "    stemmer = PorterStemmer()\n",
    "\n",
    "    def word_stemmer(text):\n",
    "        lem_text = [stemmer.stem(i) for i in text]\n",
    "        return lem_text\n",
    "    \n",
    "    train['text_tokenized'] = train['text_tokenized'].apply(word_stemmer)\n",
    "    hold['text_tokenized'] = hold['text_tokenized'].apply(word_stemmer)\n",
    "    test['text_tokenized'] = test['text_tokenized'].apply(word_stemmer)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Джоин массивов в предложения"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "train['text'] = train['text_tokenized'].apply(lambda x: \" \".join(x))\n",
    "hold['text'] = hold['text_tokenized'].apply(lambda x: \" \".join(x))\n",
    "test['text'] = test['text_tokenized'].apply(lambda x: \" \".join(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1400, 3)\n",
      "(600, 3)\n",
      "(500, 3)\n"
     ]
    }
   ],
   "source": [
    "print(train.shape)\n",
    "print(hold.shape)\n",
    "print(test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from ipywidgets import interact, interactive, interact_manual\n",
    "import ipywidgets as ip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "multilple tries one disks finally recognized video poor features available\n",
      "0\n"
     ]
    }
   ],
   "source": [
    "@interact\n",
    "def showText(x=100):\n",
    "    print(train.loc[x, 'text'])\n",
    "    print(train.loc[x, 'y'] )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Векторизация"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## WordCount"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "cv = CountVectorizer(binary=True, ngram_range=(1,2))\n",
    "\n",
    "cv.fit(train['text'])\n",
    "X_train_wc = cv.transform(train['text'])\n",
    "X_hold_wc = cv.transform(hold['text'])\n",
    "X_test_wc = cv.transform(test['text'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TF-IDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\shcherbakov2-ia\\AppData\\Local\\Continuum\\Anaconda3\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:1059: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  if hasattr(X, 'dtype') and np.issubdtype(X.dtype, np.float):\n"
     ]
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "tfv = TfidfVectorizer()\n",
    "tfv.fit(train['text'])\n",
    "X_train_tfidf = tfv.transform(train['text'])\n",
    "X_hold_tfidf = tfv.transform(hold['text'])\n",
    "X_test_tfidf = tfv.transform(test['text'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Моделирование логрегом"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression, LogisticRegressionCV\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import log_loss, roc_auc_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X_train = train['text']\n",
    "y_train = train['y']\n",
    "\n",
    "X_hold = hold['text']\n",
    "y_hold = hold['y']\n",
    "\n",
    "X_test = test['text']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Логрег на WC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "X_train_wc = cv.transform(train['text'])\n",
    "X_hold_wc = cv.transform(hold['text'])\n",
    "X_test_wc = cv.transform(test['text'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=4, error_score='raise',\n",
       "       estimator=LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
       "          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,\n",
       "          penalty='l2', random_state=None, solver='liblinear', tol=0.0001,\n",
       "          verbose=0, warm_start=False),\n",
       "       fit_params={}, iid=True, n_jobs=-1,\n",
       "       param_grid={'C': [0.01, 0.02, 0.03, 0.04, 0.05, 0.06, 0.07, 0.08, 0.09, 0.1, 0.11, 0.12, 0.13, 0.14, 0.15, 0.16, 0.17, 0.18, 0.19, 0.2, 0.21, 0.22, 0.23, 0.24, 0.25, 0.26, 0.27, 0.28, 0.29, 0.3, 0.31, 0.32, 0.33, 0.34, 0.35, 0.36, 0.37, 0.38, 0.39, 0.4, 0.41, 0.42, 0.43, 0.44, 0.45, 0.46, 0.47, 0.48..., 0.91, 0.92, 0.93, 0.94, 0.95, 0.96, 0.97, 0.98, 0.99], 'penalty': ['l1'], 'solver': ['liblinear']},\n",
       "       pre_dispatch='2*n_jobs', refit=True, return_train_score=True,\n",
       "       scoring='neg_log_loss', verbose=0)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf = LogisticRegression()\n",
    "parameters = {'C': [c/100 for c in range(1, 100, 1)],\n",
    "             'penalty':['l1'],\n",
    "             'solver':['liblinear']}\n",
    "gs = GridSearchCV(clf, parameters, n_jobs=-1, cv=4,  scoring = 'neg_log_loss')\n",
    "gs.fit(X_train_wc, train['y'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-0.5301488182061226\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'C': 0.91, 'penalty': 'l1', 'solver': 'liblinear'}"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(gs.best_score_)\n",
    "gs.best_params_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Предсказание по WC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "final_lr_wc = LogisticRegression(C=gs.best_params_['C'], penalty=gs.best_params_['penalty'])\n",
    "final_lr_wc.fit(X_train_wc, train['y'])\n",
    "test_prediction_wc = final_lr_wc.predict_proba(X_test_wc)[:,1]\n",
    "train_prediction_wc = final_lr_wc.predict_proba(X_train_wc)[:,1]\n",
    "hold_prediction_wc = final_lr_wc.predict_proba(X_hold_wc)[:,1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5152753874119351"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "log_loss(hold['y'], hold_prediction_wc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('great', 2.509769991892592),\n",
       " ('love', 2.3343573206580106),\n",
       " ('excellent', 2.1884013132977933),\n",
       " ('holds', 1.8516901526003327),\n",
       " ('happy', 1.8196696373842212),\n",
       " ('plus', 1.818419584454648),\n",
       " ('good', 1.815576405634136),\n",
       " ('pleased', 1.457741497690634),\n",
       " ('wonderful', 1.4483765473674675),\n",
       " ('perfect', 1.398836705459644),\n",
       " ('light', 1.3740674093907697),\n",
       " ('easy', 1.365403219502211),\n",
       " ('cool', 1.3351774597019752),\n",
       " ('ever', 1.2476293233787592),\n",
       " ('click', 1.1583908642807756),\n",
       " ('installed', 1.1249777854434664),\n",
       " ('pocket', 1.119218587699565),\n",
       " ('absolutely', 1.0998183411387643),\n",
       " ('awesome', 1.0994678488377412),\n",
       " ('fast', 1.0729280859655608),\n",
       " ('decent', 1.0686364599046725),\n",
       " ('price', 1.0539149196185196),\n",
       " ('amazing', 1.0386033396945016),\n",
       " ('included software', 0.9804732276969423),\n",
       " ('champ', 0.9539378056583239),\n",
       " ('well', 0.9415081763553295),\n",
       " ('nice', 0.9408181645415982),\n",
       " ('simple', 0.9109934989433419),\n",
       " ('best', 0.8932010548962418),\n",
       " ('touch', 0.7816153852497152),\n",
       " ('design', 0.7727934848531569),\n",
       " ('camera', 0.7471997324787207),\n",
       " ('screen large', 0.7454761935745061),\n",
       " ('phones', 0.7350538935416064),\n",
       " ('player', 0.731531993186914),\n",
       " ('easier', 0.7278136850404447),\n",
       " ('feature', 0.7142143455491526),\n",
       " ('needed', 0.7134088602886491),\n",
       " ('15', 0.7043496687031846),\n",
       " ('baby', 0.697291040995741),\n",
       " ('like', 0.6827217772745793),\n",
       " ('gb', 0.6798761270391034),\n",
       " ('everything', 0.6672547537921318),\n",
       " ('range', 0.6650680647285878),\n",
       " ('quality', 0.6598772774488947),\n",
       " ('ok', 0.6581659779700558),\n",
       " ('never', 0.6526291632629527),\n",
       " ('diaper', 0.6386110969033777),\n",
       " ('hitachi', 0.6188470318136835),\n",
       " ('features', 0.6078987950389502),\n",
       " ('router', 0.5983877946504182),\n",
       " ('easy use', 0.5906658441910276),\n",
       " ('digital camera', 0.5893755449430416),\n",
       " ('decided', 0.5843533107128471),\n",
       " ('definitely', 0.5770498204943627),\n",
       " ('plays', 0.5422042976646002),\n",
       " ('extremely', 0.5398851088166811),\n",
       " ('phone', 0.5336859575172637),\n",
       " ('canon', 0.5284487146005937),\n",
       " ('big', 0.528301463759237),\n",
       " ('bluetooth', 0.5270074615946821),\n",
       " ('far', 0.5196983884185793),\n",
       " ('purchased', 0.5153209274993086),\n",
       " ('small', 0.49147176110813673),\n",
       " ('micro', 0.47132693103916556),\n",
       " ('sleek', 0.4614613316871339),\n",
       " ('better', 0.4609749263438708),\n",
       " ('anywhere', 0.45291150363687904),\n",
       " ('perfectly', 0.44036334076720146),\n",
       " ('package', 0.4339663975608941),\n",
       " ('high', 0.4191059841149835),\n",
       " ('use', 0.41686616081107614),\n",
       " ('resolution', 0.37818124211460724),\n",
       " ('makes', 0.32901423040676486),\n",
       " ('full', 0.32688370071714545),\n",
       " ('6600', 0.32685118161342325),\n",
       " ('owned', 0.3256170712076203),\n",
       " ('want', 0.29764531837816854),\n",
       " ('stars', 0.2696703596601687),\n",
       " ('put', 0.2596531691097254),\n",
       " ('radio', 0.24840395980327076),\n",
       " ('overall', 0.24064171607923834),\n",
       " ('works', 0.2405667892472875),\n",
       " ('highly', 0.23676454954745574),\n",
       " ('sound', 0.23420695780878742),\n",
       " ('buying', 0.22703463140868438),\n",
       " ('sync', 0.22098378421719242),\n",
       " ('bags', 0.21014675466016244),\n",
       " ('ve', 0.18195588788784123),\n",
       " ('pictures', 0.16832547499507078)]"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Анализ фичей\n",
    "feature_coef = {word: coef for word, coef  in zip(cv.get_feature_names(), final_lr_wc.coef_[0])}\n",
    "sorted(feature_coef.items(), key=lambda x:x[1], reverse=True)[:90]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## CV на TF-IDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\shcherbakov2-ia\\AppData\\Local\\Continuum\\Anaconda3\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:1059: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  if hasattr(X, 'dtype') and np.issubdtype(X.dtype, np.float):\n"
     ]
    }
   ],
   "source": [
    "X_train_tfv = tfv.transform(train['text'])\n",
    "X_hold_tfv = tfv.transform(hold['text'])\n",
    "X_test_tfv = tfv.transform(test['text'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=4, error_score='raise',\n",
       "       estimator=LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
       "          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,\n",
       "          penalty='l2', random_state=None, solver='liblinear', tol=0.0001,\n",
       "          verbose=0, warm_start=False),\n",
       "       fit_params={}, iid=True, n_jobs=-1,\n",
       "       param_grid={'C': [0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9, 1.0, 1.1, 1.2, 1.3, 1.4, 1.5, 1.6, 1.7, 1.8, 1.9, 2.0, 2.1, 2.2, 2.3, 2.4, 2.5, 2.6, 2.7, 2.8, 2.9, 3.0, 3.1, 3.2, 3.3, 3.4, 3.5, 3.6, 3.7, 3.8, 3.9, 4.0, 4.1, 4.2, 4.3, 4.4, 4.5, 4.6, 4.7, 4.8, 4.9], 'penalty': ['l1']},\n",
       "       pre_dispatch='2*n_jobs', refit=True, return_train_score=True,\n",
       "       scoring='neg_log_loss', verbose=0)"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf_tf = LogisticRegression()\n",
    "parameters_tf = {'C': [c/10 for c in range(1, 50, 1)],\n",
    "             'penalty':['l1']}\n",
    "gs_tf = GridSearchCV(clf_tf, parameters_tf, n_jobs=-1, cv=4,  scoring = 'neg_log_loss')\n",
    "gs_tf.fit(X_train_tfv, train['y'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-0.5220529473596344\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'C': 2.7, 'penalty': 'l1'}"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(gs_tf.best_score_)\n",
    "gs_tf.best_params_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Предсказание по TF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "final_lr_tfv = LogisticRegression(C=gs_tf.best_params_['C'], penalty=gs_tf.best_params_['penalty'])\n",
    "final_lr_tfv.fit(X_train_tfv, train['y'])\n",
    "test_prediction_tfv = final_lr_tfv.predict_proba(X_test_tfv)[:,1]\n",
    "train_prediction_tfv = final_lr_tfv.predict_proba(X_train_tfv)[:,1]\n",
    "hold_prediction_tfv = final_lr_tfv.predict_proba(X_hold_tfv)[:,1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.49988259732795665"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "log_loss(hold['y'], hold_prediction_tfv)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('great', 9.77806776383256),\n",
       " ('excellent', 7.83732401055698),\n",
       " ('good', 6.598255061366012),\n",
       " ('love', 6.564718829315826),\n",
       " ('easy', 6.063305195998226),\n",
       " ('plus', 5.259378485782258),\n",
       " ('happy', 5.006061675650512),\n",
       " ('holds', 4.5101821679451275),\n",
       " ('cool', 4.172258444382701),\n",
       " ('absolutely', 3.853795188152375),\n",
       " ('decent', 3.718900594842279),\n",
       " ('well', 3.7017559942992873),\n",
       " ('wonderful', 3.563164344554508),\n",
       " ('ever', 3.5334159959964393),\n",
       " ('pocket', 3.4681413957790244),\n",
       " ('fast', 3.3879890720583403),\n",
       " ('best', 3.344392183061145),\n",
       " ('camera', 3.340254809255229),\n",
       " ('perfect', 3.2960348907108328),\n",
       " ('price', 3.2397361248218224),\n",
       " ('amazing', 3.212673798444519),\n",
       " ('pleased', 3.2083421596844732),\n",
       " ('simple', 3.137710691522902),\n",
       " ('light', 3.065817837508457),\n",
       " ('champ', 3.0211807575020546),\n",
       " ('awesome', 2.9518022404366904),\n",
       " ('gb', 2.8616226982036213),\n",
       " ('ok', 2.637601502671946),\n",
       " ('phones', 2.623325802416347),\n",
       " ('router', 2.6159195107810267)]"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Анализ фичей\n",
    "feature_coef = {word: coef for word, coef  in zip(tfv.get_feature_names(), final_lr_tfv.coef_[0])}\n",
    "sorted(feature_coef.items(), key=lambda x:x[1], reverse=True)[:30]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Моделирование ансамблем"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import math\n",
    "def get_odd(p):\n",
    "    return math.log(p/(1-p))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "ensamble_train = pd.DataFrame()\n",
    "ensamble_train['wc_logit'] = train_prediction_wc\n",
    "ensamble_train['wc_logit'] = ensamble_train['wc_logit'].apply(get_odd)\n",
    "ensamble_train['tfv_logit'] = train_prediction_tfv\n",
    "ensamble_train['tfv_logit'] = ensamble_train['tfv_logit'].apply(get_odd)\n",
    "ensamble_train['y'] = train['y'].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "ensamble_hold = pd.DataFrame()\n",
    "ensamble_hold['wc_logit'] = hold_prediction_wc\n",
    "ensamble_hold['wc_logit'] = ensamble_hold['wc_logit'].apply(get_odd)\n",
    "ensamble_hold['tfv_logit'] = hold_prediction_tfv\n",
    "ensamble_hold['tfv_logit'] = ensamble_hold['tfv_logit'].apply(get_odd)\n",
    "ensamble_hold['y'] = hold['y'].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "ps = PredefinedSplit(ensamble_hold.index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "ensamble_full = pd.concat([ensamble_hold, ensamble_train], ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "best_p = None\n",
    "best_c = None\n",
    "best_logloss=10000\n",
    "best_est = None\n",
    "for p in ['l1', 'l2']:\n",
    "    for c in [c/10000 for c in range(1, 10000, 1)]:\n",
    "        clf_ens = LogisticRegression(penalty=p, C=c)\n",
    "        clf_ens.fit(X=ensamble_train[['wc_logit', 'tfv_logit']], y = ensamble_train['y'])\n",
    "        ensemble_hold_prediction = clf_ens.predict_proba(ensamble_hold[['wc_logit', 'tfv_logit']])[:,1]\n",
    "        logloss = log_loss(ensamble_hold['y'], ensemble_hold_prediction)\n",
    "        if logloss<best_logloss:\n",
    "            best_logloss=logloss\n",
    "            best_p = p\n",
    "            best_c = c\n",
    "            best_est = clf_ens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.49810925688699553\n",
      "l1\n",
      "0.0041\n"
     ]
    }
   ],
   "source": [
    "print(best_logloss)\n",
    "print(best_p)\n",
    "print(best_c)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LogisticRegression(C=0.0041, class_weight=None, dual=False,\n",
       "          fit_intercept=True, intercept_scaling=1, max_iter=100,\n",
       "          multi_class='ovr', n_jobs=1, penalty='l1', random_state=None,\n",
       "          solver='liblinear', tol=0.0001, verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ensemble = LogisticRegression(penalty=best_p, C=best_c)\n",
    "ensemble.fit(X=ensamble_full[['wc_logit', 'tfv_logit']], y = ensamble_full['y'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "ensemble_train_prediction = ensemble.predict_proba(ensamble_train[['wc_logit', 'tfv_logit']])[:,1]\n",
    "ensemble_hold_prediction = ensemble.predict_proba(ensamble_hold[['wc_logit', 'tfv_logit']])[:,1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.4980944483893822"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "log_loss(ensamble_hold['y'], ensemble_hold_prediction)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.3486000929145205"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "log_loss(ensamble_train['y'], ensemble_train_prediction)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Сохранение  в файл"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "submission = pd.DataFrame()\n",
    "\n",
    "submission['wc_y'] = final_lr_wc.predict_proba(X_test_wc)[:,1]\n",
    "submission['tf_y'] = final_lr_tfv.predict_proba(X_test_tfv)[:,1]\n",
    "\n",
    "submission['wc_y_logit'] = submission['wc_y'].apply(get_odd)\n",
    "submission['tf_y_logit'] = submission['tf_y'].apply(get_odd)\n",
    "\n",
    "submission['ens_y'] = ensemble.predict_proba(submission[['wc_y_logit', 'tf_y_logit']])[:,1]\n",
    "submission['avg_y'] = (submission['wc_y'] + submission['tf_y'])/2\n",
    "submission.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "submission[['wc_y']].reset_index().rename({'wc_y':'y', 'index':'Id'}, axis=1).to_csv('submission/wc.csv', index=False)\n",
    "submission[['tf_y']].reset_index().rename({'tf_y':'y', 'index':'Id'}, axis=1).to_csv('submission/tfv.csv', index=False)\n",
    "submission[['ens_y']].reset_index().rename({'ens_y':'y', 'index':'Id'}, axis=1).to_csv('submission/ens.csv', index=False)\n",
    "submission[['avg_y']].reset_index().rename({'avg_y':'y', 'index':'Id'}, axis=1).to_csv('submission/avg.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  },
  "widgets": {
   "state": {
    "25458cde44194862b0ae82efeaccacd5": {
     "views": [
      {
       "cell_index": 22
      }
     ]
    }
   },
   "version": "1.2.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
