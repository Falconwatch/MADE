{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import json\n",
    "import numpy as np\n",
    "import datetime\n",
    "import os\n",
    "\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from string import punctuation\n",
    "from nltk.stem.snowball import SnowballStemmer\n",
    "punctuation=punctuation+'«»'\n",
    "\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "import xgboost\n",
    "import lightgbm as lgbm\n",
    "\n",
    "from hyperopt import hp, tpe\n",
    "from hyperopt.fmin import fmin"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Тёплый запуск"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_is_ready = os.path.exists('processed_data/data_processed.csv')\n",
    "data_merged = os.path.exists('processed_data/data.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Чтение данных"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Объединённые данные считаны\n"
     ]
    }
   ],
   "source": [
    "if not data_merged:\n",
    "    # файл с разметкой\n",
    "    with open('data/cluster_final_cut_train.json') as f:\n",
    "        train = json.load(f)\n",
    "\n",
    "    train_pd = pd.DataFrame.from_dict(train, orient='index').reset_index()\n",
    "    train_pd.columns = ['id', 'label']\n",
    "    train_pd['id']=train_pd['id'].astype(np.int64)\n",
    "    \n",
    "    \n",
    "    # файл с документами\n",
    "    with open('data/cosmo_content_storage_final_cut.jsonl', 'r', encoding='utf-8') as f:\n",
    "        lines = f.readlines()\n",
    "    documents = [json.loads(l) for l in lines]\n",
    "\n",
    "    ids = [d['doc_id'] for d in documents]\n",
    "    urls = [d['url'] for d in documents]\n",
    "    texts = [d.get('description', None) for d in documents]\n",
    "\n",
    "    documents_pd = pd.DataFrame()\n",
    "    documents_pd['id'] = ids\n",
    "    documents_pd['url'] = urls\n",
    "    documents_pd['text'] = texts\n",
    "    \n",
    "    \n",
    "    data = pd.merge(documents_pd, train_pd, left_on='id', right_on='id', how='left')\n",
    "    data.to_csv('processed_data/data.csv')\n",
    "    print('Данные объединены')\n",
    "else:\n",
    "    data = pd.read_csv('processed_data/data.csv')\n",
    "    print('Объединённые данные считаны')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Преобразование данных"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Преобразованные данные считаны\n"
     ]
    }
   ],
   "source": [
    "if not data_is_ready:\n",
    "        #Create lemmatizer and stopwords list\n",
    "    stemmer = SnowballStemmer(\"russian\") \n",
    "    russian_stopwords = stopwords.words(\"russian\")\n",
    "\n",
    "    #Preprocess function\n",
    "    def preprocess_text(text):\n",
    "        def del_punct(token):\n",
    "            return ''.join([l for l in token if l not in punctuation])\n",
    "\n",
    "        if not text:\n",
    "            return []\n",
    "\n",
    "        #в токены\n",
    "        tokens = text.lower().split(' ')\n",
    "        #удалить пунктуацию\n",
    "        tokens = [del_punct(t) for t in tokens]\n",
    "        #удалить стоп-слова\n",
    "        tokens = [t for t in tokens if t not in punctuation]\n",
    "        #стэмминг\n",
    "        tokens = [stemmer.stem(t) for t in tokens]\n",
    "        #удалить стоп-слова\n",
    "        tokens = [t for t in tokens if t not in russian_stopwords]\n",
    "\n",
    "        return tokens\n",
    "    \n",
    "    # Приведение тектс\n",
    "    data['text_arr'] = data['text'].apply(preprocess_text)\n",
    "    data['text_processed'] = data['text_arr'].apply(lambda x: ' '.join(x))\n",
    "    data.to_csv('processed_data/data_processed.csv')\n",
    "    print('Данные преобразованы')\n",
    "else:\n",
    "    data = pd.read_csv('processed_data/data_processed.csv')\n",
    "    print('Преобразованные данные считаны')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.loc[pd.isna(data['text_processed']), 'text_processed'] = ''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#сортируем по лейблу, пропуски - в конце\n",
    "data =data.sort_values(by='label').reset_index().drop(['index'], axis=1)\n",
    "\n",
    "# отюираем тренй и тест\n",
    "train = data[pd.notnull(data['label'])]\n",
    "test = data[pd.isna(data['label'])]\n",
    "\n",
    "train_size = train.shape[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# lifeHack"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "#train['text_processed']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "CountVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
       "                dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
       "                lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
       "                ngram_range=(1, 1), preprocessor=None, stop_words=None,\n",
       "                strip_accents=None, token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b',\n",
       "                tokenizer=None, vocabulary=None)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "cv = CountVectorizer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_cv = cv.fit_transform(data['text_processed'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_cv = data_cv[:train_size]\n",
    "test_cv = data_cv[train_size:]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# KNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.model_selection import cross_val_score, GridSearchCV\n",
    "from sklearn.metrics import accuracy_score, make_scorer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "knnc = KNeighborsClassifier()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "params = {'n_neighbors':[5,10,15]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "gscv = GridSearchCV(knnc, params, scoring=make_scorer(accuracy_score))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\xiaomi\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\sklearn\\model_selection\\_split.py:1978: FutureWarning: The default value of cv will change from 3 to 5 in version 0.22. Specify it explicitly to silence this warning.\n",
      "  warnings.warn(CV_WARNING, FutureWarning)\n",
      "c:\\users\\xiaomi\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\sklearn\\model_selection\\_search.py:813: DeprecationWarning: The default of the `iid` parameter will change from True to False in version 0.22 and will be removed in 0.24. This will change numeric results when test-set sizes are unequal.\n",
      "  DeprecationWarning)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv='warn', error_score='raise-deprecating',\n",
       "             estimator=KNeighborsClassifier(algorithm='auto', leaf_size=30,\n",
       "                                            metric='minkowski',\n",
       "                                            metric_params=None, n_jobs=None,\n",
       "                                            n_neighbors=5, p=2,\n",
       "                                            weights='uniform'),\n",
       "             iid='warn', n_jobs=None, param_grid={'n_neighbors': [5, 10, 15]},\n",
       "             pre_dispatch='2*n_jobs', refit=True, return_train_score=False,\n",
       "             scoring=make_scorer(accuracy_score), verbose=0)"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gscv.fit(train_cv, y=train['label'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.2000754432289702"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gscv.best_score_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'n_neighbors': 5}"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gscv.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_predicted = gscv.best_estimator_.predict(test_cv)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1192.,  294.,  429., ...,   67.,  194.,   66.])"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_predicted"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\xiaomi\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\ipykernel_launcher.py:1: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  \"\"\"Entry point for launching an IPython kernel.\n"
     ]
    }
   ],
   "source": [
    "test['knn_predicted'] = test_predicted"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "tmp = test[['id', 'knn_predicted']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "tmp.columns=['doc_id', 'cat']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\xiaomi\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\ipykernel_launcher.py:1: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  \"\"\"Entry point for launching an IPython kernel.\n"
     ]
    }
   ],
   "source": [
    "tmp['cat'] = tmp['cat'].astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>doc_id</th>\n",
       "      <th>cat</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>26510</th>\n",
       "      <td>1000029981939875422</td>\n",
       "      <td>1192</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26511</th>\n",
       "      <td>1000103932845397396</td>\n",
       "      <td>294</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26512</th>\n",
       "      <td>1000115462666782749</td>\n",
       "      <td>429</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26513</th>\n",
       "      <td>1000207870420986507</td>\n",
       "      <td>205</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26514</th>\n",
       "      <td>1000305001855188840</td>\n",
       "      <td>196</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                    doc_id   cat\n",
       "26510  1000029981939875422  1192\n",
       "26511  1000103932845397396   294\n",
       "26512  1000115462666782749   429\n",
       "26513  1000207870420986507   205\n",
       "26514  1000305001855188840   196"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tmp.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "tmp.to_csv('predictions/knn_predicted.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
