{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import json\n",
    "import numpy as np\n",
    "import datetime\n",
    "import os\n",
    "\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from string import punctuation\n",
    "from nltk.stem.snowball import SnowballStemmer\n",
    "punctuation=punctuation+'«»'\n",
    "\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "import xgboost\n",
    "import lightgbm as lgbm\n",
    "\n",
    "from hyperopt import hp, tpe\n",
    "from hyperopt.fmin import fmin"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Тёплый запуск"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_is_ready = os.path.exists('processed_data/data_processed.csv')\n",
    "data_merged = os.path.exists('processed_data/data.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Чтение данных"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Объединённые данные считаны\n"
     ]
    }
   ],
   "source": [
    "if not data_merged:\n",
    "    # файл с разметкой\n",
    "    with open('data/cluster_final_cut_train.json') as f:\n",
    "        train = json.load(f)\n",
    "\n",
    "    train_pd = pd.DataFrame.from_dict(train, orient='index').reset_index()\n",
    "    train_pd.columns = ['id', 'label']\n",
    "    train_pd['id']=train_pd['id'].astype(np.int64)\n",
    "    \n",
    "    \n",
    "    # файл с документами\n",
    "    with open('data/cosmo_content_storage_final_cut.jsonl', 'r', encoding='utf-8') as f:\n",
    "        lines = f.readlines()\n",
    "    documents = [json.loads(l) for l in lines]\n",
    "\n",
    "    ids = [d['doc_id'] for d in documents]\n",
    "    urls = [d['url'] for d in documents]\n",
    "    texts = [d.get('description', None) for d in documents]\n",
    "\n",
    "    documents_pd = pd.DataFrame()\n",
    "    documents_pd['id'] = ids\n",
    "    documents_pd['url'] = urls\n",
    "    documents_pd['text'] = texts\n",
    "    \n",
    "    \n",
    "    data = pd.merge(documents_pd, train_pd, left_on='id', right_on='id', how='left')\n",
    "    data.to_csv('processed_data/data.csv')\n",
    "    print('Данные объединены')\n",
    "else:\n",
    "    data = pd.read_csv('processed_data/data.csv')\n",
    "    print('Объединённые данные считаны')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Преобразование данных"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Преобразованные данные считаны\n"
     ]
    }
   ],
   "source": [
    "if not data_is_ready:\n",
    "        #Create lemmatizer and stopwords list\n",
    "    stemmer = SnowballStemmer(\"russian\") \n",
    "    russian_stopwords = stopwords.words(\"russian\")\n",
    "\n",
    "    #Preprocess function\n",
    "    def preprocess_text(text):\n",
    "        def del_punct(token):\n",
    "            return ''.join([l for l in token if l not in punctuation])\n",
    "\n",
    "        if not text:\n",
    "            return []\n",
    "\n",
    "        #в токены\n",
    "        tokens = text.lower().split(' ')\n",
    "        #удалить пунктуацию\n",
    "        tokens = [del_punct(t) for t in tokens]\n",
    "        #удалить стоп-слова\n",
    "        tokens = [t for t in tokens if t not in punctuation]\n",
    "        #стэмминг\n",
    "        tokens = [stemmer.stem(t) for t in tokens]\n",
    "        #удалить стоп-слова\n",
    "        tokens = [t for t in tokens if t not in russian_stopwords]\n",
    "\n",
    "        return tokens\n",
    "    \n",
    "    # Приведение тектс\n",
    "    data['text_arr'] = data['text'].apply(preprocess_text)\n",
    "    data['text_processed'] = data['text_arr'].apply(lambda x: ' '.join(x))\n",
    "    data.to_csv('processed_data/data_processed.csv')\n",
    "    print('Данные преобразованы')\n",
    "else:\n",
    "    data = pd.read_csv('processed_data/data_processed.csv')\n",
    "    print('Преобразованные данные считаны')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.loc[pd.isna(data['text_processed']), 'text_processed'] = ''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['argumentiru', 'com', 'politics', '2019', '12', '506934']"
      ]
     },
     "execution_count": 113,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import re\n",
    "\n",
    "def url_parts(url):\n",
    "    \n",
    "    def deal_points(part):\n",
    "        parts = re.findall(r\"[\\w']+\", part)\n",
    "        print(parts)\n",
    "        np.concatenate(parts, axis=0)\n",
    "        return small_parts+[' ']\n",
    "    \n",
    "    parts = re.findall(r\"[\\w']+\", url)\n",
    "    parts = [p for p in parts if p not in ['https', 'http', 'www'] and len(p)]\n",
    "    return parts[:20]\n",
    "\n",
    "url_parts('https://argumentiru.com/politics/2019/12/506934')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>id</th>\n",
       "      <th>url</th>\n",
       "      <th>text</th>\n",
       "      <th>label</th>\n",
       "      <th>text_arr</th>\n",
       "      <th>text_processed</th>\n",
       "      <th>url_arr</th>\n",
       "      <th>url_processed</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>24535</td>\n",
       "      <td>3294657291826632492</td>\n",
       "      <td>https://argumentiru.com/politics/2019/12/506934</td>\n",
       "      <td>Ещё в октябре было известно, что министр энерг...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>['ещ', 'октябр', 'известн', 'министр', 'энерге...</td>\n",
       "      <td>ещ октябр известн министр энергетик сша рик пе...</td>\n",
       "      <td>[argumentiru, com, politics, 2019, 12, 506934]</td>\n",
       "      <td>argumentiru com politics 2019 12 506934</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>31942</td>\n",
       "      <td>3972531096574318613</td>\n",
       "      <td>https://inc-news.ru/news/politics/2:13678</td>\n",
       "      <td>Рик Перри сообщил о сложении полномочий.</td>\n",
       "      <td>0.0</td>\n",
       "      <td>['рик', 'перр', 'сообщ', 'сложен', 'полномоч']</td>\n",
       "      <td>рик перр сообщ сложен полномоч</td>\n",
       "      <td>[inc, news, ru, news, politics, 2, 13678]</td>\n",
       "      <td>inc news ru news politics 2 13678</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>64817</td>\n",
       "      <td>7062567965678511105</td>\n",
       "      <td>https://dailystorm.ru/news/glava-minenergo-ssh...</td>\n",
       "      <td>Рик Перри поблагодарил своих близких и америка...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>['рик', 'перр', 'поблагодар', 'сво', 'близк', ...</td>\n",
       "      <td>рик перр поблагодар сво близк американск народ...</td>\n",
       "      <td>[dailystorm, ru, news, glava, minenergo, ssha,...</td>\n",
       "      <td>dailystorm ru news glava minenergo ssha pokinu...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>11760</td>\n",
       "      <td>2102644298978156520</td>\n",
       "      <td>http://www.moscow-post.su/news/in_world/minist...</td>\n",
       "      <td>Американский министр Рик Перри объявил о том, ...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>['американск', 'министр', 'рик', 'перр', 'объя...</td>\n",
       "      <td>американск министр рик перр объяв покинул сво ...</td>\n",
       "      <td>[moscow, post, su, news, in_world, ministr_ene...</td>\n",
       "      <td>moscow post su news in_world ministr_energetik...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0                   id  \\\n",
       "0       24535  3294657291826632492   \n",
       "1       31942  3972531096574318613   \n",
       "2       64817  7062567965678511105   \n",
       "3       11760  2102644298978156520   \n",
       "\n",
       "                                                 url  \\\n",
       "0    https://argumentiru.com/politics/2019/12/506934   \n",
       "1          https://inc-news.ru/news/politics/2:13678   \n",
       "2  https://dailystorm.ru/news/glava-minenergo-ssh...   \n",
       "3  http://www.moscow-post.su/news/in_world/minist...   \n",
       "\n",
       "                                                text  label  \\\n",
       "0  Ещё в октябре было известно, что министр энерг...    0.0   \n",
       "1           Рик Перри сообщил о сложении полномочий.    0.0   \n",
       "2  Рик Перри поблагодарил своих близких и америка...    0.0   \n",
       "3  Американский министр Рик Перри объявил о том, ...    0.0   \n",
       "\n",
       "                                            text_arr  \\\n",
       "0  ['ещ', 'октябр', 'известн', 'министр', 'энерге...   \n",
       "1     ['рик', 'перр', 'сообщ', 'сложен', 'полномоч']   \n",
       "2  ['рик', 'перр', 'поблагодар', 'сво', 'близк', ...   \n",
       "3  ['американск', 'министр', 'рик', 'перр', 'объя...   \n",
       "\n",
       "                                      text_processed  \\\n",
       "0  ещ октябр известн министр энергетик сша рик пе...   \n",
       "1                     рик перр сообщ сложен полномоч   \n",
       "2  рик перр поблагодар сво близк американск народ...   \n",
       "3  американск министр рик перр объяв покинул сво ...   \n",
       "\n",
       "                                             url_arr  \\\n",
       "0     [argumentiru, com, politics, 2019, 12, 506934]   \n",
       "1          [inc, news, ru, news, politics, 2, 13678]   \n",
       "2  [dailystorm, ru, news, glava, minenergo, ssha,...   \n",
       "3  [moscow, post, su, news, in_world, ministr_ene...   \n",
       "\n",
       "                                       url_processed  \n",
       "0            argumentiru com politics 2019 12 506934  \n",
       "1                  inc news ru news politics 2 13678  \n",
       "2  dailystorm ru news glava minenergo ssha pokinu...  \n",
       "3  moscow post su news in_world ministr_energetik...  "
      ]
     },
     "execution_count": 114,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data['url_arr'] = data['url'].apply(lambda x: url_parts(x))\n",
    "data['url_processed'] = data['url_arr'].apply(lambda x: ' '.join(x))\n",
    "data.head(4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [],
   "source": [
    "#сортируем по лейблу, пропуски - в конце\n",
    "data =data.sort_values(by='label').reset_index().drop(['index'], axis=1)\n",
    "\n",
    "# отюираем тренй и тест\n",
    "train = data[pd.notnull(data['label'])]\n",
    "test = data[pd.isna(data['label'])]\n",
    "\n",
    "train_size = train.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "20"
      ]
     },
     "execution_count": 116,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train['url_arr'].apply(len).max()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Модель на TF-IDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [],
   "source": [
    "# tf-idf\n",
    "vectorizer = TfidfVectorizer()\n",
    "train_matrix = vectorizer.fit_transform(train['url_processed'], y = train['label'])\n",
    "test_matrix = vectorizer.transform(test['url_processed'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [],
   "source": [
    "lgbm_train  = lgbm.Dataset(train_matrix, label = train['label'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3064"
      ]
     },
     "execution_count": 119,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(train['label'].unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\xiaomi\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\lightgbm\\engine.py:118: UserWarning: Found `n_estimators` in params. Will use it instead of argument\n",
      "  warnings.warn(\"Found `{}` in params. Will use it instead of argument\".format(alias))\n"
     ]
    }
   ],
   "source": [
    "lgbm_trained = lgbm.train(params={'n_estimators':5, 'objective':'multiclass', 'num_class':3064}, train_set=lgbm_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "eval() missing 2 required positional arguments: 'data' and 'name'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-122-4f2ddd3fbbcb>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mlgbm_trained\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0meval\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m: eval() missing 2 required positional arguments: 'data' and 'name'"
     ]
    }
   ],
   "source": [
    "lgbm_trained.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "def hyperopt_lgbm_score(params):\n",
    "    model = lgbm.train(lgbm_params, lgbm_train)\n",
    "    eval_result = model.eval(lgbm_train)\n",
    "    score = float(eval_result[eval_result.index('.')-1:])\n",
    "    return -score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "lgbm_params = {'objective':'multiclass', 'num_class':3064,\n",
    "              'n_estimators': 2}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r",
      "  0%|                                                                           | 0/10 [00:00<?, ?trial/s, best loss=?]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\xiaomi\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\lightgbm\\engine.py:118: UserWarning: Found `n_estimators` in params. Will use it instead of argument\n",
      "  warnings.warn(\"Found `{}` in params. Will use it instead of argument\".format(alias))\n",
      "\n",
      "job exception: eval() missing 1 required positional argument: 'name'\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "eval() missing 1 required positional argument: 'name'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-86-aade31044fb4>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m best = fmin(fn=hyperopt_lgbm_score, space=lgbm_params, \n\u001b[1;32m----> 2\u001b[1;33m             algo=tpe.suggest, max_evals=10)\n\u001b[0m\u001b[0;32m      3\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'best:'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbest\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\xiaomi\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\hyperopt\\fmin.py\u001b[0m in \u001b[0;36mfmin\u001b[1;34m(fn, space, algo, max_evals, timeout, loss_threshold, trials, rstate, allow_trials_fmin, pass_expr_memo_ctrl, catch_eval_exceptions, verbose, return_argmin, points_to_evaluate, max_queue_len, show_progressbar)\u001b[0m\n\u001b[0;32m    507\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    508\u001b[0m     \u001b[1;31m# next line is where the fmin is actually executed\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 509\u001b[1;33m     \u001b[0mrval\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mexhaust\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    510\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    511\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mreturn_argmin\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\xiaomi\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\hyperopt\\fmin.py\u001b[0m in \u001b[0;36mexhaust\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    328\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mexhaust\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    329\u001b[0m         \u001b[0mn_done\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtrials\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 330\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmax_evals\u001b[0m \u001b[1;33m-\u001b[0m \u001b[0mn_done\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mblock_until_done\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0masynchronous\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    331\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtrials\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrefresh\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    332\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\xiaomi\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\hyperopt\\fmin.py\u001b[0m in \u001b[0;36mrun\u001b[1;34m(self, N, block_until_done)\u001b[0m\n\u001b[0;32m    284\u001b[0m                 \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    285\u001b[0m                     \u001b[1;31m# -- loop over trials and do the jobs directly\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 286\u001b[1;33m                     \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mserial_evaluate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    287\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    288\u001b[0m                 \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtrials\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrefresh\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\xiaomi\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\hyperopt\\fmin.py\u001b[0m in \u001b[0;36mserial_evaluate\u001b[1;34m(self, N)\u001b[0m\n\u001b[0;32m    163\u001b[0m                 \u001b[0mctrl\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mbase\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mCtrl\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtrials\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcurrent_trial\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mtrial\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    164\u001b[0m                 \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 165\u001b[1;33m                     \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdomain\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mevaluate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mspec\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mctrl\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    166\u001b[0m                 \u001b[1;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    167\u001b[0m                     \u001b[0mlogger\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0merror\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"job exception: %s\"\u001b[0m \u001b[1;33m%\u001b[0m \u001b[0mstr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0me\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\xiaomi\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\hyperopt\\base.py\u001b[0m in \u001b[0;36mevaluate\u001b[1;34m(self, config, ctrl, attach_attachments)\u001b[0m\n\u001b[0;32m    892\u001b[0m                 \u001b[0mprint_node_on_error\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrec_eval_print_node_on_error\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    893\u001b[0m             )\n\u001b[1;32m--> 894\u001b[1;33m             \u001b[0mrval\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpyll_rval\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    895\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    896\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mrval\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mfloat\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mint\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnumber\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-83-4fa2476f2429>\u001b[0m in \u001b[0;36mhyperopt_lgbm_score\u001b[1;34m(params)\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;32mdef\u001b[0m \u001b[0mhyperopt_lgbm_score\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mparams\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      2\u001b[0m     \u001b[0mmodel\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlgbm\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlgbm_params\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlgbm_train\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 3\u001b[1;33m     \u001b[0meval_result\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0meval\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlgbm_train\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      4\u001b[0m     \u001b[0mscore\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mfloat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0meval_result\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0meval_result\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mindex\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'.'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m-\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[1;33m-\u001b[0m\u001b[0mscore\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mTypeError\u001b[0m: eval() missing 1 required positional argument: 'name'"
     ]
    }
   ],
   "source": [
    "best = fmin(fn=hyperopt_lgbm_score, space=lgbm_params, \n",
    "            algo=tpe.suggest, max_evals=10)\n",
    "print('best:')\n",
    "print(best)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "#lgbm_trained = lgbm.train(lgbm_params, lgbm_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "1/0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Submission"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_submission = pd.read_csv('data/sample.txt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "##\n",
    "submission = sample_submission"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(61858, 2)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "submission.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "submission.to_csv('submissions/submission_{}'.format(datetime.datetime.now().strftime('%y%m%d_%H%m%S')), index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
